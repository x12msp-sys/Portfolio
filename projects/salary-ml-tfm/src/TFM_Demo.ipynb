{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db5ed564",
   "metadata": {},
   "source": [
    "# TFM — Explicabilidad Avanzada (SHAP + PDP) y Productivización\n",
    "Autor: **Marcos Sánchez Pozo**\n",
    "\n",
    "Este notebook:\n",
    "- Entrena (RandomForest y opcional XGBoost).\n",
    "- Genera **SHAP** (summary + bar + dependence plots).\n",
    "- Genera **PDP** (partial dependence de las top features).\n",
    "- Define **`predict_salary`** y guarda artefactos en `artifacts/`.\n",
    "- Incluye un **protitpo Gradio** (UI) para probar el modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bb02d515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP version: 0.48.0\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# Configuración básica\n",
    "# ==============================================\n",
    "\n",
    "!pip install -q pandas numpy scikit-learn shap xgboost joblib gradio matplotlib\n",
    "import os, json, joblib, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "    HAS_XGB = True\n",
    "except Exception:\n",
    "    HAS_XGB = False\n",
    "import shap\n",
    "print(\"SHAP version:\", shap.__version__)\n",
    "PLOTS_DIR = \"TFM_plots\"; ARTIFACTS_DIR = \"artifacts\"\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True); os.makedirs(ARTIFACTS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0a7e8374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quitando columnas que fugarían el target: ['salary']\n",
      "Target: salary_in_usd | Categóricas: 6 | Numéricas: 2\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# CARGA DEL DATASET \n",
    "# ===============================================\n",
    "DATA_PATH = \"DATA/salaries.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Detecta columna objetivo\n",
    "if 'salary_eur' in df.columns: \n",
    "    target_col = 'salary_eur'\n",
    "elif 'salary_in_usd' in df.columns: \n",
    "    target_col = 'salary_in_usd'\n",
    "elif 'salary' in df.columns: \n",
    "    target_col = 'salary'\n",
    "else:\n",
    "    raise ValueError(\"No encuentro columna de salario.\")\n",
    "\n",
    "# Limpia columnas irrelevantes\n",
    "df = df.drop(columns=[c for c in ['salary_currency','Unnamed: 0','index'] if c in df.columns], errors='ignore')\n",
    "\n",
    "# Quita del dataset toda columna salarial que NO sea el objetivo\n",
    "leak_cols = {'salary', 'salary_in_usd', 'salary_in_euro', 'salary_eur'}\n",
    "leak_cols.discard(target_col)  # deja la del target\n",
    "cols_a_quitar = [c for c in leak_cols if c in df.columns]\n",
    "if cols_a_quitar:\n",
    "    print(\"Quitando columnas que fugarían el target:\", cols_a_quitar)\n",
    "    df = df.drop(columns=cols_a_quitar)\n",
    "\n",
    "# Construye X, y\n",
    "y = df[target_col].astype(float)\n",
    "X = df.drop(columns=[target_col])\n",
    "\n",
    "# Identifica tipos\n",
    "cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "num_cols = X.select_dtypes(include=['number','bool']).columns.tolist()\n",
    "print(\"Target:\", target_col, \"| Categóricas:\", len(cat_cols), \"| Numéricas:\", len(num_cols))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "66ebbaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# Preprocesado\n",
    "# ===============================================\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_cols),\n",
    "        ('num', StandardScaler(), num_cols)\n",
    "    ], remainder='drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9ff5785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# ENTRENAMIENTO Y EVALUACIÓN \n",
    "# ===============================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Intentar usar HistGradientBoosting (rápido). Si no existe, caer a GradientBoosting.\n",
    "try:\n",
    "    from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "    HAS_HGB = True\n",
    "except ImportError:\n",
    "    from sklearn.ensemble import GradientBoostingRegressor\n",
    "    HAS_HGB = False\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return mean_squared_error(y_true, y_pred) ** 0.5  # compat sin squared=\n",
    "\n",
    "# --------- Modo rápido ---------\n",
    "FAST = True          \n",
    "MAX_FILAS = 15000\n",
    "\n",
    "if FAST and len(X_train) > MAX_FILAS:\n",
    "    X_train_ = X_train.sample(MAX_FILAS, random_state=42)\n",
    "    y_train_ = y_train.loc[X_train_.index]\n",
    "else:\n",
    "    X_train_, y_train_ = X_train, y_train\n",
    "\n",
    "models, results = {}, []\n",
    "\n",
    "# 1) RandomForest LIGERO (sin paralelización: n_jobs=1 para evitar error de loky/wmic)\n",
    "rf = Pipeline(steps=[\n",
    "    ('prep', preprocessor),\n",
    "    ('model', RandomForestRegressor(\n",
    "        n_estimators=150,   # antes 400\n",
    "        max_depth=12,       # limita profundidad\n",
    "        n_jobs=1,           # <-- clave: evita loky y el error de wmic\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "rf.fit(X_train_, y_train_)\n",
    "pred_rf = rf.predict(X_test)\n",
    "results.append({\n",
    "    \"modelo\": \"RandomForest_fast\",\n",
    "    \"MAE\": mean_absolute_error(y_test, pred_rf),\n",
    "    \"RMSE\": rmse(y_test, pred_rf),\n",
    "    \"R2\": r2_score(y_test, pred_rf)\n",
    "})\n",
    "models[\"RandomForest_fast\"] = rf\n",
    "\n",
    "# 2) Boosting rápido (no usa n_jobs)\n",
    "if HAS_HGB:\n",
    "    gbr = Pipeline(steps=[\n",
    "        ('prep', preprocessor),\n",
    "        ('model', HistGradientBoostingRegressor(\n",
    "            max_depth=8,\n",
    "            max_iter=300,\n",
    "            learning_rate=0.06,\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "else:\n",
    "    from sklearn.ensemble import GradientBoostingReg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dbe4c815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo: RandomForest_fast\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelo</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest_fast</td>\n",
       "      <td>47000.190348</td>\n",
       "      <td>64859.54485</td>\n",
       "      <td>0.25827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              modelo           MAE         RMSE       R2\n",
       "0  RandomForest_fast  47000.190348  64859.54485  0.25827"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mejor modelo\n",
    "res_df = pd.DataFrame(results).sort_values(\"R2\", ascending=False)\n",
    "best_name = res_df.iloc[0]['modelo']; best_model = models[best_name]\n",
    "print(\"Mejor modelo:\", best_name); res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "05443db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº features: 402\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# SHAP\n",
    "# ===============================================\n",
    "\n",
    "sample_idx = np.random.RandomState(42).choice(len(X_test), size=min(1000, len(X_test)), replace=False)\n",
    "X_sample = X_test.iloc[sample_idx]\n",
    "X_sample_prep = best_model.named_steps['prep'].transform(X_sample)\n",
    "model_step = best_model.named_steps['model']\n",
    "is_tree_model = hasattr(model_step, \"predict\") and any(kw in model_step.__class__.__name__.lower() for kw in [\"forest\",\"xgb\",\"boost\",\"tree\"])\n",
    "if is_tree_model:\n",
    "    explainer = shap.TreeExplainer(model_step); shap_values = explainer.shap_values(X_sample_prep)\n",
    "else:\n",
    "    bg_idx = np.random.RandomState(42).choice(X_sample_prep.shape[0], size=min(100, X_sample_prep.shape[0]), replace=False)\n",
    "    explainer = shap.KernelExplainer(model_step.predict, X_sample_prep[bg_idx])\n",
    "    shap_values = explainer.shap_values(X_sample_prep[:200])\n",
    "cat_names = best_model.named_steps['prep'].named_transformers_['cat'].get_feature_names_out(cat_cols).tolist() if len(cat_cols)>0 else []\n",
    "feat_names = cat_names + num_cols\n",
    "print(\"Nº features:\", len(feat_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "99950a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardados: shap_summary.png, shap_bar.png\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# SHAP summary + bar \n",
    "# ===============================================\n",
    "plt.figure(figsize=(10,6)); shap.summary_plot(shap_values, X_sample_prep, feature_names=feat_names, show=False)\n",
    "plt.tight_layout(); plt.savefig(os.path.join(PLOTS_DIR, \"shap_summary.png\"), dpi=150, bbox_inches='tight'); plt.close()\n",
    "plt.figure(figsize=(10,6)); shap.summary_plot(shap_values, X_sample_prep, feature_names=feat_names, plot_type=\"bar\", show=False)\n",
    "plt.tight_layout(); plt.savefig(os.path.join(PLOTS_DIR, \"shap_bar.png\"), dpi=150, bbox_inches='tight'); plt.close()\n",
    "print(\"Guardados: shap_summary.png, shap_bar.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ba580d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado: TFM_plots\\shap_dependence_employee_residence_US.png\n",
      "Guardado: TFM_plots\\shap_dependence_experience_level_MI.png\n",
      "Guardado: TFM_plots\\shap_dependence_experience_level_EN.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===============================================\n",
    "# SHAP dependence (top 3) \n",
    "# ===============================================\n",
    "importances = np.mean(np.abs(shap_values), axis=0)\n",
    "top_idx = np.argsort(importances)[::-1][:3]\n",
    "top_feats = [feat_names[i] for i in top_idx]\n",
    "for f in top_feats:\n",
    "    plt.figure(figsize=(8,5)); shap.dependence_plot(f, shap_values, X_sample_prep, feature_names=feat_names, show=False)\n",
    "    plt.tight_layout(); out = os.path.join(PLOTS_DIR, f\"shap_dependence_{str(f).replace('/', '_').replace(' ', '_')}.png\")\n",
    "    plt.savefig(out, dpi=150, bbox_inches='tight'); plt.close(); print(\"Guardado:\", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "51a1c606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado: TFM_plots\\pdp_top3_fast.png\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# PDP de las top 3 (versión rápida) \n",
    "# ===============================================\n",
    "\n",
    "\n",
    "import numpy as np, os, matplotlib.pyplot as plt\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "# 1) Usa solo el modelo interno y pretransforma una vez\n",
    "prep = best_model.named_steps['prep']\n",
    "model = best_model.named_steps['model']\n",
    "\n",
    "X_train_prep = prep.transform(X_train)\n",
    "\n",
    "# 2) Mapea nombres -> índices en el espacio transformado\n",
    "feat_to_idx = {name: i for i, name in enumerate(feat_names)}\n",
    "idxs = [feat_to_idx[f] for f in top_feats if f in feat_to_idx]\n",
    "\n",
    "if len(idxs) == 0:\n",
    "    raise ValueError(\"Ninguna de las top_feats aparece en feat_names. Recalcula top_feats tras SHAP.\")\n",
    "\n",
    "# 3) Submuestrea filas para acelerar\n",
    "rng = np.random.RandomState(42)\n",
    "sub = min(3000, X_train_prep.shape[0])  # ajusta a 1000 si aún va lento\n",
    "sub_idx = rng.choice(X_train_prep.shape[0], size=sub, replace=False)\n",
    "X_sub = X_train_prep[sub_idx]\n",
    "\n",
    "# 4) PDP con menos puntos de rejilla\n",
    "fig, axes = plt.subplots(nrows=len(idxs), ncols=1, figsize=(9, 4*len(idxs)))\n",
    "if len(idxs) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, f_idx in zip(axes, idxs):\n",
    "    PartialDependenceDisplay.from_estimator(\n",
    "        model,\n",
    "        X_sub,\n",
    "        [f_idx],               # índice de la feature transformada\n",
    "        ax=ax,\n",
    "        kind='average',\n",
    "        grid_resolution=20     # (por defecto suele ser 100). Baja = más rápido\n",
    "        # No pasamos n_jobs para evitar problemas de loky/wmic en Windows\n",
    "    )\n",
    "    ax.set_title(f\"PDP: {feat_names[f_idx]}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "out = os.path.join(PLOTS_DIR, \"pdp_top3_fast.png\")\n",
    "plt.savefig(out, dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"Guardado:\", out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c1658021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicción ejemplo: 174530.9471381858\n",
      "Artefactos guardados en 'artifacts/'\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# Función de predicción y guardado de artefactos \n",
    "# ===============================================\n",
    "\n",
    "# Normalización mínima para que coincida con lo que vio el modelo\n",
    "_EMPLOYMENT_MAP = {\n",
    "    \"FULL-TIME\": \"FT\", \"FULL TIME\": \"FT\",\n",
    "    \"PART-TIME\": \"PT\", \"PART TIME\": \"PT\",\n",
    "    \"CONTRACT\": \"CT\", \"FREELANCE\": \"FL\"\n",
    "}\n",
    "\n",
    "def _norm_row(row: dict, expected_features):\n",
    "    r = {k: row.get(k, np.nan) for k in expected_features}\n",
    "    # mayúsculas en categóricas principales\n",
    "    for c in [\"experience_level\", \"employment_type\", \"employee_residence\",\n",
    "              \"company_location\", \"company_size\"]:\n",
    "        if r.get(c) is not None:\n",
    "            r[c] = str(r[c]).strip().upper()\n",
    "    # mapear empleo legible -> código del dataset\n",
    "    if r.get(\"employment_type\") in _EMPLOYMENT_MAP:\n",
    "        r[\"employment_type\"] = _EMPLOYMENT_MAP[r[\"employment_type\"]]\n",
    "    # asegurar remote_ratio numérico en [0, 100]\n",
    "    if \"remote_ratio\" in r and r[\"remote_ratio\"] is not None:\n",
    "        try:\n",
    "            r[\"remote_ratio\"] = float(r[\"remote_ratio\"])\n",
    "        except Exception:\n",
    "            r[\"remote_ratio\"] = 0.0\n",
    "        r[\"remote_ratio\"] = max(0.0, min(100.0, r[\"remote_ratio\"]))\n",
    "    return r\n",
    "\n",
    "EXPECTED_FEATURES = X.columns.tolist()\n",
    "def predict_salary(input_dict, pipeline=best_model, expected_features=EXPECTED_FEATURES):\n",
    "    row = {k: input_dict.get(k, np.nan) for k in expected_features}\n",
    "    row = _norm_row(row, expected_features)   # <<< AÑADIDO\n",
    "    df_in = pd.DataFrame([row], columns=expected_features)\n",
    "    return float(pipeline.predict(df_in)[0])\n",
    "\n",
    "# Demo\n",
    "example = {}\n",
    "for c in EXPECTED_FEATURES:\n",
    "    if str(X_train[c].dtype) == 'object' and X_train[c].dropna().shape[0] > 0:\n",
    "        example[c] = X_train[c].dropna().astype(str).mode().iloc[0]\n",
    "    else:\n",
    "        example[c] = float(np.nanmedian(X_train[c])) if c in X_train.columns else 0.0\n",
    "print(\"Predicción ejemplo:\", predict_salary(example))\n",
    "joblib.dump(best_model, os.path.join(ARTIFACTS_DIR, \"salary_pipeline.joblib\"))\n",
    "with open(os.path.join(ARTIFACTS_DIR, \"meta.json\"), \"w\") as f:\n",
    "    json.dump({\"best_model\": best_name, \"features\": EXPECTED_FEATURES, \"target\": target_col}, f, indent=2)\n",
    "print(\"Artefactos guardados en 'artifacts/'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d432380e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7871\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7871/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===============================================\n",
    "# DEMO GRADIO \n",
    "# ===============================================\n",
    "\n",
    "import gradio as gr, numpy as np, pandas as pd, sys, subprocess, json\n",
    "from pathlib import Path\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 0) pycountry lista completa de países\n",
    "# -------------------------------------------------\n",
    "def _get_pycountry():\n",
    "    try:\n",
    "        import pycountry\n",
    "        return pycountry\n",
    "    except Exception:\n",
    "        try:\n",
    "            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"pycountry\"], check=False)\n",
    "            import pycountry\n",
    "            return pycountry\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "pycountry = _get_pycountry()\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 1) Etiquetas amigables y mapeos\n",
    "# -------------------------------------------------\n",
    "EMPLOYMENT_TO_LABEL = {\"FT\": \"Full-time\", \"PT\": \"Part-time\", \"CT\": \"Contract\", \"FL\": \"Freelance\"}\n",
    "LABEL_TO_EMPLOYMENT = {v: k for k, v in EMPLOYMENT_TO_LABEL.items()}\n",
    "\n",
    "SIZE_TO_LABEL  = {\"S\": \"Small\", \"M\": \"Medium\", \"L\": \"Large\"}\n",
    "LABEL_TO_SIZE  = {v: k for k, v in SIZE_TO_LABEL.items()}\n",
    "\n",
    "# Experiencia: etiquetas legibles <-> códigos del dataset\n",
    "EXP_CODE_TO_LABEL = {\"EN\": \"Entry (EN)\", \"MI\": \"Mid (MI)\", \"SE\": \"Senior (SE)\", \"EX\": \"Executive (EX)\"}\n",
    "EXP_LABEL_TO_CODE = {v: k for k, v in EXP_CODE_TO_LABEL.items()}\n",
    "\n",
    "# Fallback de países si no hay pycountry \n",
    "COUNTRY_FALLBACK = {\n",
    " \"US\":\"United States\",\"GB\":\"United Kingdom\",\"ES\":\"Spain\",\"FR\":\"France\",\"DE\":\"Germany\",\n",
    " \"IT\":\"Italy\",\"PT\":\"Portugal\",\"NL\":\"Netherlands\",\"BE\":\"Belgium\",\"IE\":\"Ireland\",\n",
    " \"CA\":\"Canada\",\"AU\":\"Australia\",\"NZ\":\"New Zealand\",\"MX\":\"Mexico\",\"BR\":\"Brazil\",\n",
    " \"AR\":\"Argentina\",\"CL\":\"Chile\",\"CO\":\"Colombia\",\"PE\":\"Peru\",\"PH\":\"Philippines\",\n",
    " \"PL\":\"Poland\",\"CZ\":\"Czechia\",\"SE\":\"Sweden\",\"NO\":\"Norway\",\"FI\":\"Finland\",\n",
    " \"DK\":\"Denmark\",\"CH\":\"Switzerland\",\"AT\":\"Austria\",\"RO\":\"Romania\",\"HU\":\"Hungary\",\n",
    " \"GR\":\"Greece\",\"TR\":\"Turkey\",\"IL\":\"Israel\",\"AE\":\"United Arab Emirates\",\"SA\":\"Saudi Arabia\",\n",
    " \"IN\":\"India\",\"SG\":\"Singapore\",\"JP\":\"Japan\",\"KR\":\"South Korea\",\"CN\":\"China\",\"ZA\":\"South Africa\",\n",
    " \"RU\":\"Russia\",\"UA\":\"Ukraine\",\"XK\":\"Kosovo\"\n",
    "}\n",
    "\n",
    "def all_countries():\n",
    "    pairs = []\n",
    "    if pycountry:\n",
    "        for c in pycountry.countries:\n",
    "            try:\n",
    "                pairs.append((c.alpha_2.upper(), c.name))\n",
    "            except Exception:\n",
    "                pass\n",
    "        if not any(code == \"XK\" for code, _ in pairs):\n",
    "            pairs.append((\"XK\", \"Kosovo\"))\n",
    "    else:\n",
    "        pairs = list(COUNTRY_FALLBACK.items())\n",
    "        for col in (\"employee_residence\", \"company_location\"):\n",
    "            if col in X_train.columns:\n",
    "                for code in map(str, X_train[col].dropna().unique()):\n",
    "                    code = code.upper().strip()\n",
    "                    if not any(code == c for c, _ in pairs):\n",
    "                        pairs.append((code, code))\n",
    "    return sorted(pairs, key=lambda t: t[1])\n",
    "\n",
    "_country_pairs = all_countries()\n",
    "COUNTRY_LABELS = [name for _, name in _country_pairs]\n",
    "COUNTRY_L2C = {name: code for code, name in _country_pairs}\n",
    "\n",
    "# Quitar 'salary' de la interfaz\n",
    "if \"salary\" in EXPECTED_FEATURES:\n",
    "    EXPECTED_FEATURES = [c for c in EXPECTED_FEATURES if c != \"salary\"]\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2) Helper formato €\n",
    "# -------------------------------------------------\n",
    "EUR_SYMBOL = \"€\"\n",
    "def format_eur(x):\n",
    "    try:\n",
    "        x = float(x)\n",
    "        s = f\"{x:,.2f}\".replace(\",\", \"X\").replace(\".\", \",\").replace(\"X\", \".\")\n",
    "        return f\"{s} {EUR_SYMBOL}\"\n",
    "    except Exception:\n",
    "        return \"—\"\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 3) ¿El modelo espera remote_cat o remote_ratio?\n",
    "# -------------------------------------------------\n",
    "def _modelo_espera_remote_cat():\n",
    "    try:\n",
    "        meta_path = Path(\"artifacts\") / \"preproc_meta.json\"\n",
    "        if meta_path.exists():\n",
    "            meta = json.loads(meta_path.read_text(encoding=\"utf-8\"))\n",
    "            cats = set(meta.get(\"categorical_columns\", []))\n",
    "            return \"remote_cat\" in cats\n",
    "    except Exception:\n",
    "        pass\n",
    "    # Si no hay meta: miramos las features\n",
    "    return \"remote_cat\" in EXPECTED_FEATURES\n",
    "\n",
    "USES_REMOTE_CAT = _modelo_espera_remote_cat()\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 4) Función de inferencia (kwargs) + mapeos robustos\n",
    "# -------------------------------------------------\n",
    "def _predict_interface(**kwargs):\n",
    "    # 1) Recoge solo lo que el modelo espera\n",
    "    data = {k: kwargs.get(k) for k in EXPECTED_FEATURES}\n",
    "\n",
    "    # 2) Mapeos legibles -> códigos del modelo\n",
    "    if \"employment_type\" in data and data[\"employment_type\"]:\n",
    "        data[\"employment_type\"] = LABEL_TO_EMPLOYMENT.get(str(data[\"employment_type\"]).strip(), data[\"employment_type\"])\n",
    "\n",
    "    if \"company_size\" in data and data[\"company_size\"]:\n",
    "        data[\"company_size\"] = LABEL_TO_SIZE.get(str(data[\"company_size\"]).strip(), data[\"company_size\"])\n",
    "\n",
    "    if \"employee_residence\" in data and data[\"employee_residence\"]:\n",
    "        data[\"employee_residence\"] = COUNTRY_L2C.get(str(data[\"employee_residence\"]).strip(), data[\"employee_residence\"])\n",
    "\n",
    "    if \"company_location\" in data and data[\"company_location\"]:\n",
    "        data[\"company_location\"] = COUNTRY_L2C.get(str(data[\"company_location\"]).strip(), data[\"company_location\"])\n",
    "\n",
    "    # --- NUEVO: asegurar que job_title coincide con el training (evita que no cambie la predicción) ---\n",
    "    if \"job_title\" in data and data[\"job_title\"]:\n",
    "        jt = str(data[\"job_title\"]).strip()\n",
    "        if \"job_title\" in X_train.columns:\n",
    "            choices = X_train[\"job_title\"].dropna().astype(str).unique().tolist()\n",
    "            if jt not in choices:\n",
    "                by_cf = {c.casefold(): c for c in choices}\n",
    "                data[\"job_title\"] = by_cf.get(jt.casefold(), choices[0])\n",
    "\n",
    "    if \"experience_level\" in data and data[\"experience_level\"]:\n",
    "        val = str(data[\"experience_level\"]).strip()\n",
    "        # etiqueta legible -> código (EN/MI/SE/EX)\n",
    "        data[\"experience_level\"] = EXP_LABEL_TO_CODE.get(val, val.upper())\n",
    "\n",
    "    # 3) Remote: crear/validar según lo que use el modelo\n",
    "    if USES_REMOTE_CAT:\n",
    "        # crear remote_cat a partir de remote_ratio si\n",
    "        if \"remote_cat\" not in data:\n",
    "            rr = kwargs.get(\"remote_ratio\", None)\n",
    "            try:\n",
    "                r = float(rr)\n",
    "            except Exception:\n",
    "                r = None\n",
    "            if r is None:\n",
    "                rc = \"Híbrido (1–99%)\"\n",
    "            elif r == 0:\n",
    "                rc = \"Presencial (0%)\"\n",
    "            elif r == 100:\n",
    "                rc = \"Remoto (100%)\"\n",
    "            else:\n",
    "                rc = \"Híbrido (1–99%)\"\n",
    "            data[\"remote_cat\"] = rc\n",
    "        # si el modelo no espera remote_ratio, lo quitamos del payload\n",
    "        if \"remote_ratio\" in data and \"remote_ratio\" not in EXPECTED_FEATURES:\n",
    "            data.pop(\"remote_ratio\", None)\n",
    "    else:\n",
    "        # el modelo espera remote_ratio numérico en [0,100]\n",
    "        if \"remote_ratio\" in data:\n",
    "            try:\n",
    "                r = float(data[\"remote_ratio\"])\n",
    "                data[\"remote_ratio\"] = min(100, max(0, r))\n",
    "            except Exception:\n",
    "                data[\"remote_ratio\"] = 0\n",
    "        # quitamos remote_cat si no se usa\n",
    "        data.pop(\"remote_cat\", None)\n",
    "\n",
    "    # 4) Predicción con tu pipeline persistido\n",
    "    out = predict_salary(data)\n",
    "\n",
    "    # 5) Extraer número y formatear a €\n",
    "    try:\n",
    "        val = None\n",
    "        if hasattr(out, \"columns\"):\n",
    "            for col in [\"pred_salary_eur\", \"pred_salary\", \"pred_salary_usd\"]:\n",
    "                if col in out.columns:\n",
    "                    val = float(out[col].iloc[0])\n",
    "                    if col == \"pred_salary_usd\":\n",
    "                        val *= 0.92  # conversión simple si solo devuelves USD\n",
    "                    break\n",
    "        if val is None:\n",
    "            val = float(out)\n",
    "        return format_eur(val)\n",
    "    except Exception as e:\n",
    "        print(\"Error formateando predicción:\", e)\n",
    "        return \"—\"\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 5) Construcción de inputs\n",
    "# -------------------------------------------------\n",
    "def _default_or_none(seq, prefer=None):\n",
    "    if prefer and prefer in seq: return prefer\n",
    "    return seq[0] if seq else None\n",
    "\n",
    "inputs = []\n",
    "for c in EXPECTED_FEATURES:\n",
    "    label = c.replace(\"_\", \" \").title()\n",
    "\n",
    "    if c == \"employment_type\":\n",
    "        labels = list(EMPLOYMENT_TO_LABEL.values())\n",
    "        inputs.append(gr.Dropdown(choices=labels, label=label,\n",
    "                                  value=_default_or_none(labels, \"Full-time\"),\n",
    "                                  allow_custom_value=False))\n",
    "\n",
    "    elif c == \"experience_level\":\n",
    "        exp_labels = [EXP_CODE_TO_LABEL.get(\"EN\",\"EN\"), EXP_CODE_TO_LABEL.get(\"MI\",\"MI\"),\n",
    "                      EXP_CODE_TO_LABEL.get(\"SE\",\"SE\"), EXP_CODE_TO_LABEL.get(\"EX\",\"EX\")]\n",
    "        inputs.append(gr.Dropdown(choices=exp_labels, label=\"Experience Level\",\n",
    "                                  value=_default_or_none(exp_labels, \"Mid (MI)\"),\n",
    "                                  allow_custom_value=False))\n",
    "\n",
    "    elif c in (\"employee_residence\", \"company_location\"):\n",
    "        inputs.append(gr.Dropdown(choices=COUNTRY_LABELS, label=label,\n",
    "                                  value=_default_or_none(COUNTRY_LABELS, \"Spain\"),\n",
    "                                  allow_custom_value=False))\n",
    "\n",
    "    elif c == \"company_size\":\n",
    "        labels = list(SIZE_TO_LABEL.values())\n",
    "        inputs.append(gr.Dropdown(choices=labels, label=label,\n",
    "                                  value=_default_or_none(labels, \"Medium\"),\n",
    "                                  allow_custom_value=False))\n",
    "\n",
    "    elif c == \"remote_cat\":\n",
    "        rc_labels = [\"Presencial (0%)\", \"Híbrido (1–99%)\", \"Remoto (100%)\"]\n",
    "        inputs.append(gr.Dropdown(choices=rc_labels, label=\"Remote Mode\",\n",
    "                                  value=_default_or_none(rc_labels, \"Remoto (100%)\"),\n",
    "                                  allow_custom_value=False))\n",
    "\n",
    "    elif c == \"remote_ratio\":\n",
    "        \n",
    "        default_val = 100\n",
    "        inputs.append(gr.Number(label=label, value=default_val))\n",
    "\n",
    "    elif str(X_train.get(c, pd.Series(dtype=object)).dtype) == \"object\":\n",
    "        vals = sorted(list(map(str, X_train[c].dropna().unique())))[:100] if c in X_train.columns else []\n",
    "        if not vals: vals = [\"N/A\"]\n",
    "        inputs.append(gr.Dropdown(choices=vals, label=label, value=vals[0]))\n",
    "\n",
    "    else:\n",
    "        default_val = float(np.nanmedian(X_train[c])) if c in X_train.columns else 0.0\n",
    "        inputs.append(gr.Number(label=label, value=default_val))\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 6) Interface: mapear posicionales \n",
    "# -------------------------------------------------\n",
    "# --- construir inputs EXACTAMENTE en el orden de EXPECTED_FEATURES ---\n",
    "def _make_component_for(feat):\n",
    "    import gradio as gr\n",
    "    # Ajusta componentes por nombre de feature (usa tus mapeos existentes)\n",
    "    if feat == \"employment_type\":\n",
    "        return gr.Dropdown(choices=list(EMPLOYMENT_TO_LABEL.values()),\n",
    "                           value=list(EMPLOYMENT_TO_LABEL.values())[0],\n",
    "                           label=\"employment_type\")\n",
    "    if feat == \"company_size\":\n",
    "        return gr.Dropdown(choices=list(SIZE_TO_LABEL.values()),\n",
    "                           value=list(SIZE_TO_LABEL.values())[0],\n",
    "                           label=\"company_size\")\n",
    "    if feat in (\"employee_residence\", \"company_location\"):\n",
    "        # COUNTRY_LABELS ya lo tienes creado con pycountry/fallback\n",
    "        default_lbl = COUNTRY_LABELS[0] if COUNTRY_LABELS else \"Spain\"\n",
    "        return gr.Dropdown(choices=COUNTRY_LABELS, value=default_lbl, label=feat)\n",
    "    if feat == \"experience_level\":\n",
    "        return gr.Dropdown(choices=list(EXP_CODE_TO_LABEL.values()),\n",
    "                           value=list(EXP_CODE_TO_LABEL.values())[1],\n",
    "                           label=\"experience_level\")\n",
    "    if feat == \"remote_ratio\":\n",
    "        return gr.Slider(minimum=0, maximum=100, step=1, value=100, label=\"remote_ratio\")\n",
    "    # Heurística: categórica vs numérica\n",
    "    if feat in X_train.columns and X_train[feat].dtype == \"object\":\n",
    "        ch = sorted(X_train[feat].dropna().astype(str).unique().tolist())\n",
    "        val = ch[0] if ch else \"\"\n",
    "        return gr.Dropdown(choices=ch[:2000], value=val, allow_custom_value=True, label=feat)\n",
    "    elif feat in X_train.columns:\n",
    "        return gr.Number(value=float(np.nanmedian(pd.to_numeric(X_train[feat], errors=\"coerce\"))),\n",
    "                         label=feat)\n",
    "    else:\n",
    "        return gr.Textbox(value=\"\", label=feat)\n",
    "\n",
    "inputs = [_make_component_for(f) for f in EXPECTED_FEATURES]\n",
    "\n",
    "# --- wrapper que mapea valores \n",
    "def _call(*vals):\n",
    "    data = dict(zip(EXPECTED_FEATURES, vals))\n",
    "    return _predict_interface(**data)\n",
    "\n",
    "# CSS: más ancho y menos espacio vertical\n",
    "CSS = \"\"\"\n",
    ".gradio-container { max-width: 1600px !important; margin: 0 auto !important; }\n",
    ".gradio-container .gr-row { gap: 10px !important; }\n",
    ".gradio-container .gr-column { gap: 10px !important; }\n",
    ".gr-textbox input, .gr-number input { height: 48px; font-size: 1.05rem; }\n",
    "\"\"\"\n",
    "\n",
    "with gr.Blocks(title=\"Estimador de Salario (TFM)\", css=CSS) as demo:\n",
    "    gr.Markdown(\"## Estimador de Salario (TFM)\\nIntroduce el perfil; internamente se mapean etiquetas a los códigos del modelo.\")\n",
    "\n",
    "    with gr.Row():\n",
    "        # ---------- Inputs en 3 columnas ----------\n",
    "        with gr.Column(scale=3):\n",
    "            inputs_grid = []\n",
    "            with gr.Row():\n",
    "                col1 = gr.Column()\n",
    "                col2 = gr.Column()\n",
    "                col3 = gr.Column()\n",
    "            cols = [col1, col2, col3]\n",
    "            for i, feat in enumerate(EXPECTED_FEATURES):\n",
    "                with cols[i % 3]:\n",
    "                    inputs_grid.append(_make_component_for(feat))\n",
    "\n",
    "        # ---------- Salida a la derecha ----------\n",
    "        with gr.Column(scale=2):\n",
    "            out_box = gr.Textbox(label=\"Predicción salario (€)\")\n",
    "            btn = gr.Button(\"Predecir\", variant=\"primary\")\n",
    "            btn.click(\n",
    "                lambda *vals: _predict_interface(**dict(zip(EXPECTED_FEATURES, vals))),\n",
    "                inputs=inputs_grid,\n",
    "                outputs=out_box\n",
    "            )\n",
    "\n",
    "\n",
    "demo.launch()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "35663487-f01b-44d6-9125-4ab7c6e80dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK -> C:\\Users\\x12ms\\TFM\\exports\\TFM_Demo_export.html\n"
     ]
    }
   ],
   "source": [
    "# Exportar EL .ipynb a HTML legible (sin código)\n",
    "from pathlib import Path\n",
    "import nbformat\n",
    "from nbconvert import HTMLExporter\n",
    "\n",
    "NB_NAME = \"TFM_Demo.ipynb\"   \n",
    "nb_path = Path(NB_NAME).resolve()\n",
    "assert nb_path.exists(), f\"No existe: {nb_path}\"\n",
    "\n",
    "nb = nbformat.read(nb_path, as_version=4)\n",
    "\n",
    "exp = HTMLExporter()\n",
    "exp.exclude_input = True\n",
    "exp.exclude_output_prompt = True\n",
    "exp.exclude_input_prompt = True\n",
    "exp.embed_images = True\n",
    "\n",
    "body, _ = exp.from_notebook_node(nb)\n",
    "\n",
    "out_dir = Path(\"exports\"); out_dir.mkdir(parents=True, exist_ok=True)\n",
    "out_file = out_dir / f\"{nb_path.stem}_export.html\"\n",
    "out_file.write_text(body, encoding=\"utf-8\")\n",
    "print(\"OK ->\", out_file.resolve())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
